{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import time\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def GPT_response(messages, model_name):\n",
    "    token_num_count = 0\n",
    "    client = OpenAI( # Enter Your API Key Here\n",
    "        api_key='...' \n",
    "    )\n",
    "    # for item in messages:\n",
    "    #     token_num_count += len(enc.encode(item[\"content\"]))\n",
    "\n",
    "    try:\n",
    "        result = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            temperature=0.0,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        try:\n",
    "            result = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            temperature=0.0,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "            )\n",
    "        except:\n",
    "            try:\n",
    "                print(f'{model_name} Waiting 60 seconds for API query')\n",
    "                time.sleep(60)\n",
    "                result = client.chat.completions.create(\n",
    "                    model=model_name,\n",
    "                    messages=messages,\n",
    "                    temperature = 0.0,\n",
    "                    top_p=1,\n",
    "                    frequency_penalty=0,\n",
    "                    presence_penalty=0\n",
    "                )\n",
    "            except:\n",
    "                return 'Out of tokens', token_num_count\n",
    "    #token_num_count += len(enc.encode(result.choices[0].message.content))\n",
    "    return result.choices[0].message.content, token_num_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Backtracking line search is an optimization technique used to find an appropriate step size in iterative optimization algorithms, particularly in gradient descent methods. The goal of backtracking line search is to ensure that each step taken in the optimization process leads to a sufficient decrease in the objective function, thereby improving convergence.\\n\\n### Key Concepts:\\n\\n1. **Objective Function**: This is the function that you want to minimize (or maximize). In many cases, it is denoted as \\\\( f(x) \\\\), where \\\\( x \\\\) is the variable or parameter vector.\\n\\n2. **Gradient**: The gradient \\\\( \\\\nabla f(x) \\\\) provides the direction of steepest ascent of the function \\\\( f \\\\). In optimization, we often move in the opposite direction of the gradient to minimize the function.\\n\\n3. **Step Size**: The step size (or learning rate) determines how far we move in the direction of the negative gradient. Choosing an appropriate step size is crucial for the convergence of the optimization algorithm.\\n\\n### Backtracking Line Search Algorithm:\\n\\nThe backtracking line search algorithm works as follows:\\n\\n1. **Initialization**: Start with an initial guess for the step size \\\\( \\\\alpha \\\\) (often set to 1) and define parameters:\\n   - \\\\( \\\\beta \\\\) (a constant in the range \\\\( (0, 1) \\\\)) that reduces the step size.\\n   - \\\\( \\\\sigma \\\\) (a small positive constant, typically between 0 and 0.5) that determines the sufficient decrease condition.\\n\\n2. **Sufficient Decrease Condition**: The algorithm checks whether the following condition holds:\\n   \\\\[\\n   f(x - \\\\alpha \\\\nabla f(x)) \\\\leq f(x) - \\\\sigma \\\\alpha \\\\|\\\\nabla f(x)\\\\|^2\\n   \\\\]\\n   This condition ensures that the new point \\\\( x - \\\\alpha \\\\nabla f(x) \\\\) has a sufficiently lower function value compared to the current point \\\\( x \\\\).\\n\\n3. **Backtracking**: If the condition is not satisfied, reduce the step size by multiplying it by \\\\( \\\\beta \\\\) (i.e., \\\\( \\\\alpha = \\\\beta \\\\alpha \\\\)) and check the condition again.\\n\\n4. **Termination**: The process continues until the sufficient decrease condition is satisfied. At this point, the step size \\\\( \\\\alpha \\\\) is accepted, and the optimization algorithm proceeds to update the current point.\\n\\n### Advantages:\\n\\n- **Adaptive Step Size**: Backtracking line search adapts the step size based on the local behavior of the objective function, which can lead to better convergence properties compared to using a fixed step size.\\n- **Simplicity**: The method is straightforward to implement and does not require complex calculations.\\n\\n### Applications:\\n\\nBacktracking line search is commonly used in various optimization algorithms, including:\\n- Gradient descent\\n- Newton's method\\n- Quasi-Newton methods\\n\\nOverall, backtracking line search is a practical and effective technique for ensuring that optimization algorithms make meaningful progress towards finding the minimum of a function.\",\n",
       " 628)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "           {\"role\": \"user\", \"content\": 'What is backtracking line search?'}]\n",
    "\n",
    "GPT_response(message, \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
